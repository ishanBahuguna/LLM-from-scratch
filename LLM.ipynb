{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8M9BsC+RJxiBh+nbw9Wqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishanBahuguna/LLM-from-scratch/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading in a short story as text smaple into python**"
      ],
      "metadata": {
        "id": "ZyIpod3-AMwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 : Creating Tokens"
      ],
      "metadata": {
        "id": "6n9RQ_eDGXrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\" , \"r\" , encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character: \", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "mCEoqMPZGicG",
        "outputId": "c8ad067e-46a4-44bd-a24b-7e929fff4d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'the-verdict.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3840005950.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the-verdict.txt\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of character: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'the-verdict.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r'(\\s)' , text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "g-1XLjVxG6mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.]|\\s)' , text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "z1T92Nv3HcnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing whitespaces depends on the problem statement , removeing them decreases computational cost but it can be useful if the dataset is like python code with indentation"
      ],
      "metadata": {
        "id": "XASxXohTJkDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "S84Q3v1XH9AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result = re.split(r'([,:;.?_!()\\']|--|\\s)' , text);\n",
        "result  = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "iKdIlXQGKHdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying tokenization on raw_text"
      ],
      "metadata": {
        "id": "52XBHZbjLnzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,:;.?_!()\\']|--|\\s)' , raw_text);\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "print(preprocessed[:90])\n"
      ],
      "metadata": {
        "id": "bWmE3OEMLm9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "id": "jQfaOExNM0vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have tokenize the text data and now we will be creating vocabulary from it which is the set of tokens sorted in order and then assign unique id's to the tokens which is called token ID"
      ],
      "metadata": {
        "id": "pU3PQab4wu0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 : Creating token ID's"
      ],
      "metadata": {
        "id": "NznEhQcLxc82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "\n",
        "print(vocab_size)\n"
      ],
      "metadata": {
        "id": "90PObht3xzE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f0e86c43-1467-4abc-8d6b-384d4c0b44d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessed' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-953452548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessed' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating vocab by assigning tokenID's to the tokens\n",
        "\n",
        "vocab = {token : integer for integer , token in enumerate(all_words)}\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "AaTWa93Txo4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#e.g : creating token ids\n",
        "\n",
        "eg_word = sorted((\"heelo\" , \"how\" , \".\" , \"you\"))\n",
        "vocab = {token : integer for integer , token in enumerate(eg_word)}\n",
        "\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "m-hynqLDdowQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i , item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i >= 50:\n",
        "    break;"
      ],
      "metadata": {
        "id": "TlFI67jzy3X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "consider the vocab like a encoder which converts words into token ids but later we also need decoder so the the numeric output from the LLM can be converted into text again"
      ],
      "metadata": {
        "id": "3GU9X1qu0Amp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class SimpleTokenizerV1:\n",
        "  def __init__(self , vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s , i in vocab.items()}\n",
        "\n",
        "  def encode(self , text):\n",
        "    preprocessed = re.split(r'([,:;.?_!()\\']|--|\\s)' , text);\n",
        "\n",
        "    preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self , ids):\n",
        "    text = \" \".join([self.int_to_str[id] for id in ids])\n",
        "    # Replace spaces before specified punctuations\n",
        "    text = re.sub(r'\\s+([,.?''()\\'])' , r'\\1' , text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "HbUV1KNr1B9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "Gv2dd3Bo-sS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "id": "w4qn7vgk_9Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simple tokenizer was able to encode and decode the training text successfuly whihc was present in the vocab but what if the word is not present in the vocab?"
      ],
      "metadata": {
        "id": "5KPmozMQRm75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea?\" # Hello is not present in the vocab\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "_cliiOOQRymH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above error is because the vocab used here is very small whereas LLMs use very large datasets and a concept of Special Text tokens"
      ],
      "metadata": {
        "id": "I-fTe4sXSQIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding special text tokens to the vocab"
      ],
      "metadata": {
        "id": "89eikZvqUCII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\"  , \"<|unk|>\"])\n",
        "\n",
        "vocab = {token:integer for integer, token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "7CeTc0F9UHsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "id": "vUuGu7ioUq4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "4okpaapKU-CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updated tokenizer class:\n",
        "\n",
        "class SimpleTokenizerV2:\n",
        "  def __init__(self , vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self , text):\n",
        "    preprocessed = re.split(r'([,:;.?_!()\\']|--|\\s)' , text);\n",
        "\n",
        "    #two strip() --> remove leading and trailing white spaces\n",
        "    # as well as removes the empty strings\n",
        "    preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "\n",
        "    preprocessed = [\n",
        "        item if item in self.str_to_int\n",
        "        else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self , ids):\n",
        "    text = \" \".join(self.int_to_str[id] for id in ids)\n",
        "    # Replace spaces before the specified punctuations\n",
        "    text = re.sub(r'\\s+([,.?''()\\'])' , r'\\1' , text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "23ybXIFpVSzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "\n",
        "text1 = \"Hello , do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text1 , text2))\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "id": "X1ng2zrhoYcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "ol1b_lYWo13m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "ZkCQ4SUnpMJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Byte Pair Encoding"
      ],
      "metadata": {
        "id": "pnnT1jLkQyBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directly using a library called tiktoken for BPE which is written in rust"
      ],
      "metadata": {
        "id": "ST5OTSPKQ8oY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken #used by openAI"
      ],
      "metadata": {
        "id": "UVNcWwMjQ4Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version : \" , importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "id": "T4uBY2mjRWKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "s2uCBnYTR4NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of this tokenizer is similar to SimpleTokenizerV2 which we have implemented earlier"
      ],
      "metadata": {
        "id": "fpSNmFymSMB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"Hello , do you like tea? <|endoftext|> In the sunlit terraces \" \"of someunknownPlace.\")\n",
        "\n",
        "integers = tokenizer.encode(text , allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "id": "K3kq2b66SIEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "id": "bgsQJc8tT3Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another example to illustrate how BPE algo works"
      ],
      "metadata": {
        "id": "T6xg78DlVH-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "id": "ZTRUVIe_VOpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING INPUT-TARGET PAIRS"
      ],
      "metadata": {
        "id": "vuBm5D3-p15E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement data loader that fetches the input-target pairs using a sliding window approach"
      ],
      "metadata": {
        "id": "NYE8pO4dqdIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\" , \"r\" , encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(\"Vocab size : \" , len(enc_text))"
      ],
      "metadata": {
        "id": "yMog7XBVqpIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "3RmQsr0prp8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4 # this size is actually very big , in initial gpt it was 1024\n",
        "\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x : {x}\")\n",
        "print(f\"y :      {y}\")"
      ],
      "metadata": {
        "id": "xGqNY4Jhrfjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1 , context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(context , \" ----> \" , desired)"
      ],
      "metadata": {
        "id": "0ECBixHJyn-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1 , context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(tokenizer.decode(context) , \" ----> \" , tokenizer.decode([desired]))"
      ],
      "metadata": {
        "id": "T9LLXre6zcf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "pLGNVzjvEA2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "nrAFbli5nVoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "GDaFS_uRvABC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset , DataLoader\n",
        "# todo : learn pytorch and Dataset class\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self , txt , tokenizer, max_length , stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    # tokenize the entire text\n",
        "    token_ids = tokenizer.encode(txt , allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    # use a sliding window to chunk the book info overlapping sequences of max_length : auto-regression model\n",
        "    for i in range(0 , len(token_ids) - max_length , stride):\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self , idx):\n",
        "    return self.input_ids[idx] , self.target_ids[idx]"
      ],
      "metadata": {
        "id": "B50Sk2-RnsPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batches example:\n",
        "\n",
        "ex1\n",
        "ex2\n",
        "\n",
        "ex3\n",
        "ex4\n",
        "\n",
        "ex5\n",
        "ex6\n",
        "\n",
        "ex7 --> not satifying size of batch=2 so drop for small dataset may create instability in training the dataset"
      ],
      "metadata": {
        "id": "Lep6ZAPMs0Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pBNzjKm6tHUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# txt --> training dataset\n",
        "# stride --> by how many places to move ahead(here 1)\n",
        "\n",
        "def create_dataloader_v1(txt ,batch_size=2 , max_length=256\n",
        "                         , stride=128 , shuffle=True , drop_last=True , num_workers=0 ):\n",
        "\n",
        "  # initialize the tokenizer\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  # create dataset\n",
        "  dataset = GPTDatasetV1(txt , tokenizer , max_length , stride)\n",
        "\n",
        "  # create dataloader : todo\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      drop_last = drop_last,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "75mHtd3hoZe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\" , \"r\" , encoding='utf-8') as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "jBuFhWQ3uiWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "eaf6380b-84a0-40b6-82c6-026b6846744d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'the-verdict.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1945205806.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the-verdict.txt\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'the-verdict.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = create_dataloader_v1(raw_text , batch_size=1 , max_length=4 , stride=1 , shuffle=False)\n",
        "\n",
        "data_iter = iter(data_loader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "FIBo4X75vNEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "HdPvaSj8wmd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above two dataloader batches it can be seen that there are smiliar tokens in the first and second batches which may lead to overfitting of LLM so we use a greater stride size"
      ],
      "metadata": {
        "id": "jgjeUnakw12m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = create_dataloader_v1(raw_text , batch_size=1 , max_length=4 , stride=4 , shuffle=False)\n",
        "\n",
        "data_iter = iter(data_loader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "anuaVqDhxHym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "56GeWZR0xUia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8 , max_length=4, stride=4\n",
        "    , shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "input , targets = next(data_iter)\n",
        "print(\"Inputs : \\n\" , input)\n",
        "print(\"\\nTargets : \\n\" , targets)"
      ],
      "metadata": {
        "id": "FjdygvxzcJfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Token embeddings"
      ],
      "metadata": {
        "id": "_dXEwiZ_eF4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO : LLMs are deep NN so learn how NN works\n",
        "\n",
        "We convert tokenIds into vector embeddings which are initialzed with random values and optimzied during the training of LLM by adjusting wts"
      ],
      "metadata": {
        "id": "QFalqYI3gH_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])\n",
        "# fox-2 , jumps-3 , over-5 , dog-1\n",
        "\n",
        "vocab_size = 6 # for simplicity taken 6 otherwise use tiktoken vocab size\n",
        "# tiktoken vocab size --> tokenizer.n_vocab\n",
        "output_dim = 3 # for simplicity\n",
        "\n",
        "torch.manual_seed(123) # read about this\n",
        "\n",
        "# embedding_layer = torch.nn.Embedding(vocab_size , output_dim)\n",
        "embedding_layer = torch.nn.Embedding(tokenizer.n_vocab , output_dim)"
      ],
      "metadata": {
        "id": "Kb4kdjfKgjoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight) ## random values\n",
        "#embedding_layer act as a lookup table for input_id"
      ],
      "metadata": {
        "id": "R57Myd4thFUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(torch.tensor([3])) # since python is 0-indexed"
      ],
      "metadata": {
        "id": "EE-m_FedimVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(input_ids)"
      ],
      "metadata": {
        "id": "TwTDDFZDi8-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding word positions\n"
      ],
      "metadata": {
        "id": "eQOpeFI_Ud9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The need of encoding positions is that the LLMs self attention mechanism is position agnostic and treats same token at different position to be same which should not happen e.g fox jumps over a fox"
      ],
      "metadata": {
        "id": "s0XBsD-cYQq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257 # size of tiktoken vocab\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size , output_dim)\n",
        "# check out the implementation of embedding from the book"
      ],
      "metadata": {
        "id": "k_uwjw_iUola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weights of embedding layer : \\n\" , token_embedding_layer.weight)"
      ],
      "metadata": {
        "id": "rynXwaUZea_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text , batch_size=8,\n",
        "    max_length=max_length ,\n",
        "    stride = max_length , shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs , targets = next(data_iter) # dataloader returns tensor which can be feeded to embedding layer"
      ],
      "metadata": {
        "id": "nKq5L3clVDbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token ids : \\n \" , inputs)\n",
        "\n",
        "print(\"\\n Input shape: \\n\" , inputs.shape)\n",
        "\n",
        "print(\"\\n Targer: \\n\" , targets)\n",
        "\n",
        "print(\"\\n Targets Shaper: \\n\" , targets.shape)"
      ],
      "metadata": {
        "id": "hz3QllFjXFf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input is feeded to the embedding layer\n",
        "token_embeddings = token_embedding_layer(inputs)\n",
        "token_embeddings.shape"
      ],
      "metadata": {
        "id": "ZKMFIaXVbEOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings[0,0]"
      ],
      "metadata": {
        "id": "cZRa3Cj5cELl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For positional encoding GPT simply used another embedding layer\n",
        "In case of Lamma used rotational embedding layer"
      ],
      "metadata": {
        "id": "llrgvBlk3ZOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length , output_dim)"
      ],
      "metadata": {
        "id": "FTzE_uTY3e9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coding Attention Mechanism**"
      ],
      "metadata": {
        "id": "ZmJ18lfW7n7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Attention Mechanism without tangible weights"
      ],
      "metadata": {
        "id": "Kdqjs6VnN6n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "1hU0_cmkRKzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are representation of text in terms of multidimensional arrays\n",
        "\n",
        "0-D tensor : scalar\n",
        "\n",
        "1-D tensor : vector\n",
        "\n",
        "2-D tensor : matrix\n",
        "\n",
        "3-D tesnor : 3rd order tensor\n",
        "\n",
        ".\n",
        "\n",
        ".\n"
      ],
      "metadata": {
        "id": "Bx__HCzosRHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89],  # Your        (x^1)\n",
        "     [0.55, 0.87, 0.66],  # journey     (x^2)\n",
        "     [0.57, 0.85, 0.64],  # starts      (x^3)\n",
        "     [0.22, 0.58, 0.33],  # with        (x^4)\n",
        "     [0.77, 0.25, 0.10],  # one         (x^5)\n",
        "     [0.05, 0.80, 0.55]]  # step        (x^6)\n",
        ")\n"
      ],
      "metadata": {
        "id": "nI3F30eaRL-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product of two vectors\n",
        "\n",
        "input_1 = inputs[0]\n",
        "input_2 = inputs[1]\n",
        "\n",
        "print(\"Input 1 : \" , input_1)\n",
        "print(\"Input 2 : \" , input_2)\n",
        "\n",
        "print(\"Multiplication : \" , input_1 * input_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBqjo-U7RcNS",
        "outputId": "5b93b1b8-9f92-4c1a-a2df-fff7b10c9f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 1 :  tensor([0.4300, 0.1500, 0.8900])\n",
            "Input 2 :  tensor([0.5500, 0.8700, 0.6600])\n",
            "Multiplication :  tensor([0.2365, 0.1305, 0.5874])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product = 0.43*0.55 + 0.15*0.87 + 0.89*0.66\n",
        "print(dot_product)\n",
        "\n",
        "#dot product in terms on tensor:\n",
        "print(torch.dot(input_1 , input_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQLICAoTSCFq",
        "outputId": "8d825251-c69c-4f75-c7d4-070f84769ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9544\n",
            "tensor(0.9544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product of each token w.r.t x2:\n",
        "input_2 = inputs[1]\n",
        "\n",
        "for input in inputs:\n",
        "  print(torch.dot(input , input_2))\n",
        "\n",
        "\n",
        "res = 0\n",
        "\n",
        "for input in inputs:\n",
        "  res += torch.dot(input , input_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGCGhACWSVN4",
        "outputId": "49aefcee-a6d3-41c6-8a31-2bed468954de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9544)\n",
            "tensor(1.4950)\n",
            "tensor(1.4754)\n",
            "tensor(0.8434)\n",
            "tensor(0.7070)\n",
            "tensor(1.0865)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors have fixed sized and it is generally considered inefficient to inc or dev there size , whereas list in python have dynamic size\n",
        "\n",
        "\n",
        "The dot product between two vectors is used to understand the similarity between them"
      ],
      "metadata": {
        "id": "pSv5WKwHYZiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product with respect to a query(query was x2 in above e.g) = attention scores\n",
        "\n",
        "input_query = inputs[1]\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "for idx , x_i in enumerate(inputs):\n",
        "  attn_scores_2[idx] = torch.dot(x_i , input_query)\n",
        "\n",
        "\n",
        "print(attn_scores_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFZRIJ2pWyOo",
        "outputId": "1283c4f5-0c7a-409e-8949-8210f2ef51cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a real attention mechanism the attentions wts are trained in NN\n"
      ],
      "metadata": {
        "id": "9dEeoO57Z9IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the attn_score to be 1:\n",
        "\n",
        "attn_wt_2_tmp = attn_scores_2 / attn_scores_2.sum() # learn about softmax function\n",
        "\n",
        "attn_wt_2_tmp\n"
      ],
      "metadata": {
        "id": "yLa2geoXaDmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c97b9c-06a9-4679-e147-498262b279b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_wt_2_tmp.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pvmvurUuMS-",
        "outputId": "67b99131-58bd-4eb5-e96d-bf5aab591333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: need for normalizing the scores or wts , pytorch , softmax function , significane of dot product\n",
        "\n",
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim = 0)\n",
        "\n",
        "softmax_naive(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STD_Ptm8vIKh",
        "outputId": "b260ba81-e67c-44ec-a90e-437662cd006e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_wts_2 = torch.softmax(attn_scores_2 , dim=0)\n",
        "attn_wts_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZOTK_axvglS",
        "outputId": "07ca8b8b-ca2e-48e8-d6cd-7e56ceec0c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating context vector as same length of the query vector: Multiplying attention wts with the respective vector and yeilding the vector of same length as of query vector by summing the result of multiplication"
      ],
      "metadata": {
        "id": "aUDSqWFq0e5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(input_query.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Judxfuu0d0e",
        "outputId": "8b7ac80c-e611-4cff-814b-9f73bf4175fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = torch.zeros(input_query.shape)\n",
        "\n",
        "# it is called self attention mechanism becoz the current word in translation is laser focused to itself w.r.t to others using attention scores\n",
        "for idx , x_i in enumerate(inputs):\n",
        "  print(f\"{attn_wts_2[idx]}  ---->  {x_i}\")\n",
        "  context_vec_2 += attn_wts_2[idx] * x_i\n",
        "  print(context_vec_2)\n",
        "\n",
        "context_vec_2\n",
        "\n",
        "# what is happening in above loop:\n",
        "\"\"\"\n",
        "inputs =   [[1,2,3],\n",
        "           [4,5,6],\n",
        "           [7,8,9],\n",
        "           [10,11,12]]\n",
        "\n",
        "attn_score = [1,2,3,4]\n",
        "\n",
        "context_vec = (1 * [1,2,3]) + (2 * [4,5,6]) + (3 * [7,8,9]) + (4 * [10,11,12])\n",
        "            = [60 , 80 , 90]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "its_EmQc0dv1",
        "outputId": "c383ca19-9332-426c-e48b-c1358a161376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13854756951332092  ---->  tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.0596, 0.0208, 0.1233])\n",
            "0.2378913015127182  ---->  tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.1904, 0.2277, 0.2803])\n",
            "0.23327402770519257  ---->  tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.3234, 0.4260, 0.4296])\n",
            "0.12399158626794815  ---->  tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.3507, 0.4979, 0.4705])\n",
            "0.10818186402320862  ---->  tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.4340, 0.5250, 0.4813])\n",
            "0.15811361372470856  ---->  tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating context vector for all inputs"
      ],
      "metadata": {
        "id": "xrML3Moqj75q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89],  # Your        (x^1)\n",
        "     [0.55, 0.87, 0.66],  # journey     (x^2)\n",
        "     [0.57, 0.85, 0.64],  # starts      (x^3)\n",
        "     [0.22, 0.58, 0.33],  # with        (x^4)\n",
        "     [0.77, 0.25, 0.10],  # one         (x^5)\n",
        "     [0.05, 0.80, 0.55]]  # step        (x^6)\n",
        ")\n",
        "\n",
        "print(f\"Input Tensor : \\n\\n{inputs}\")\n",
        "# creating empty tensor to store attention scores\n",
        "attn_scores = torch.empty([inputs.shape[0] , inputs.shape[0]])\n",
        "attn_wts = torch.empty([inputs.shape[0] , inputs.shape[0]])\n",
        "\n",
        "\n",
        "# calculating attention scores for each input tensor\n",
        "for i , x_i in enumerate(inputs):\n",
        "  for j , x_j in enumerate(inputs):\n",
        "    attn_scores[i][j] = torch.dot(x_i , x_j)\n",
        "\n",
        "print(f\"\\n\\n\\nAttention sores before normalization: \\n\\n {attn_scores}\")\n",
        "\n",
        "# normalizing attention scores:\n",
        "# for i , x_i in enumerate(attn_scores):\n",
        "#   attn_wts[i] = torch.softmax(x_i , dim=0)\n",
        "\n",
        "# dim =1 => softmax is applied row wise which is similar to above loop\n",
        "attn_wts = torch.softmax(attn_scores , dim=1)\n",
        "\n",
        "# attn_wts = torch.softmax(attn_scores , dim=0) --> dim = 0 => apply softmax column wise\n",
        "\n",
        "print(f\"\\nAttention sores after normalization: \\n\\n{attn_wts}\")\n",
        "\n",
        "# context vector to store each of the input vector\n",
        "temp = torch.zeros(inputs.shape)\n",
        "context_vec = torch.empty(inputs.shape)\n",
        "\n",
        "print(f\"\\n\\nContext vector initialization : \\n\\n{context_vec}\")\n",
        "\n",
        "\n",
        "for i in range(0 , inputs.shape[0]):\n",
        "  temp = torch.zeros(inputs.shape[1])\n",
        "  for idx , input in enumerate(inputs):\n",
        "    temp += input * attn_wts[i][idx]\n",
        "\n",
        "  if i == 1:\n",
        "    print(f\"\\nContext vector : \\n {temp}\")\n",
        "\n",
        "  context_vec[i] = temp\n",
        "\n",
        "\n",
        "print(f\"\\n\\nContext vector after processing with attention weights :\\n\\n{context_vec}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8YQzgtUkAvA",
        "outputId": "d89f3892-815e-447a-bda3-f2b0fdb4d801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor : \n",
            "\n",
            "tensor([[0.4300, 0.1500, 0.8900],\n",
            "        [0.5500, 0.8700, 0.6600],\n",
            "        [0.5700, 0.8500, 0.6400],\n",
            "        [0.2200, 0.5800, 0.3300],\n",
            "        [0.7700, 0.2500, 0.1000],\n",
            "        [0.0500, 0.8000, 0.5500]])\n",
            "\n",
            "\n",
            "\n",
            "Attention sores before normalization: \n",
            "\n",
            " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
            "\n",
            "Attention sores after normalization: \n",
            "\n",
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
            "\n",
            "\n",
            "Context vector initialization : \n",
            "\n",
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 1.4013e-45, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 6.8664e-44, 0.0000e+00],\n",
            "        [3.5535e-16, 0.0000e+00, 4.4354e-15],\n",
            "        [4.5537e-41, 4.2039e-45, 0.0000e+00]])\n",
            "\n",
            "Context vector : \n",
            " tensor([0.4419, 0.6515, 0.5683])\n",
            "\n",
            "\n",
            "Context vector after processing with attention weights :\n",
            "\n",
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some techniques:\n",
        "\n",
        "attn_scores = inputs @ inputs.T # matrix multiplication with transpose and it is more optimized than using two loops"
      ],
      "metadata": {
        "id": "47B0eUj_l_C7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9195a630-68b0-409b-cf3c-cb1cc0cbc40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_wts = torch.softmax(attn_scores , dim = 1)\n",
        "attn_wts.sum(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrSw-DKpRJQh",
        "outputId": "6cee8d8f-a98d-44f2-e2e5-c70201492c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec = attn_wts @ inputs\n",
        "context_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fhtgZcMRxsF",
        "outputId": "2928a2c6-8faf-40f6-d994-70dd9c1cc0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self attention with trainable weights"
      ],
      "metadata": {
        "id": "52e4Q67tSQvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89],  # Your        (x^1)\n",
        "     [0.55, 0.87, 0.66],  # journey     (x^2)\n",
        "     [0.57, 0.85, 0.64],  # starts      (x^3)\n",
        "     [0.22, 0.58, 0.33],  # with        (x^4)\n",
        "     [0.77, 0.25, 0.10],  # one         (x^5)\n",
        "     [0.05, 0.80, 0.55]]  # step        (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "jC4t6kCOXvaf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2\n",
        "\n",
        "print(f\"x_2 : {x_2} \\n\\n d_in : {d_in}\\n\\n d_out : {d_out}\")"
      ],
      "metadata": {
        "id": "OoXtr3CuScVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# initializing wt query using nn parameter because it makes the tensor which is trainable => requires gradient = true\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in , d_out))\n",
        "W_query"
      ],
      "metadata": {
        "id": "GThclRsbXeeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_key = torch.nn.Parameter(torch.rand(d_in , d_out))\n",
        "W_key"
      ],
      "metadata": {
        "id": "XoiDT0ItX1j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_value = torch.nn.Parameter(torch.rand(d_in , d_out))\n",
        "W_value"
      ],
      "metadata": {
        "id": "GiRBg37qYZWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "query_2"
      ],
      "metadata": {
        "id": "igoq0GBkchV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "odbZg-eSs1zq",
        "outputId": "8f09f037-ecc9-4e9f-a07d-249065534979"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3868859786.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    }
  ]
}